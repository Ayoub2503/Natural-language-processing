{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlAfI8mCWAf3"
   },
   "source": [
    "# Transfer learning for NLP\n",
    "## ALTEGRAD - Lab session 3\n",
    "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
    "##### 23 November 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IqukuIe0Rb_c"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FF6fjkqgN39"
   },
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p0cj9WkSFQwl"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        '''\n",
    "        ntokens: the size of vocabulary\n",
    "        nhid: the hidden dimension of the model.\n",
    "        We assume that embedding_dim = nhid\n",
    "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        nhead: the number of heads in the multiheadattention models\n",
    "        dropout: the dropout value\n",
    "         '''\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
    "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid, dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
    "        self.nhid = nhid\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
    "        src = self.pos_encoder(src) #fill me\n",
    "        output = self.transformer_encoder(src, src_mask)#fill me\n",
    "        return output\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, nhid, nclasses):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.decoder = nn.Linear(nhid, nclasses) #fill me\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.decoder(src)\n",
    "        return output\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)#fill me\n",
    "        self.classifier = ClassificationHead(nhid, nclasses) #fill me \n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # base model\n",
    "        x = self.base.forward(src, src_mask) #fill me\n",
    "        # classifier model\n",
    "        output = self.classifier.forward(x)#fill me\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kt2QQohaFZry"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, nhid)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfEYHJx2JW6l"
   },
   "source": [
    "Let's verify if our model works, by applying one inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhb2gkUhJMR0",
    "outputId": "1ec2c1af-42b3-4d8f-8d90-7c468cf1a26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 100])\n"
     ]
    }
   ],
   "source": [
    "ntokens = 100 # the size of vocabulary\n",
    "nhid = 200  # hidden dimension\n",
    "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # the number of heads in the multiheadattention models\n",
    "dropout = 0  # the dropout value\n",
    "\n",
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
    "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
    "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
    "out = model.forward(dummy_input, src_mask)\n",
    "\n",
    "print(out.shape) # is it the right shape?   #yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i74NN897Fcit"
   },
   "source": [
    "## Vocabulary and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qjd26ghWuff",
    "outputId": "fe98b182-27c3-47be-e8ea-438400e89429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 17:56:18--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 577587 (564K) [text/plain]\n",
      "Saving to: ‘dict.txt.1’\n",
      "\n",
      "\r",
      "dict.txt.1            0%[                    ]       0  --.-KB/s               \r",
      "dict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2021-11-30 17:56:19 (13.5 MB/s) - ‘dict.txt.1’ saved [577587/577587]\n",
      "\n",
      "▁d 1\n",
      "es 1\n",
      "▁l 1\n",
      "en 1\n",
      "on 1\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
    "!head -5 dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFdH_-JeFbGA",
    "outputId": "e819b9b6-bde0-40fb-beb8-b22d791c4f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁trop\n"
     ]
    }
   ],
   "source": [
    "path_vocab = \"dict.txt\"\n",
    "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
    "lens = len(token2ind)\n",
    "with open(path_vocab, \"r\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        word = line.split()[0].strip()\n",
    "        token2ind[word] = idx + lens  #fill me\n",
    "\n",
    "ind2token = {ind: token for token, ind in token2ind.items()} #fill me\n",
    "\n",
    "print(ind2token[1111])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOExGODajN8p"
   },
   "source": [
    "### Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Y0jN-Ar9i5Q1"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_documents,\n",
    "        path_labels=None,\n",
    "        token2ind={},\n",
    "        max_len=512,\n",
    "        task=\"language_modeling\",\n",
    "    ):\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "        self.token2ind = token2ind\n",
    "        self.documents = []\n",
    "        self.labels = []\n",
    "        with open(path_documents, \"r\") as f1:\n",
    "            for line in f1:\n",
    "                self.documents.append(line.strip())\n",
    "        if task == \"classification\":\n",
    "            with open(path_labels, \"r\") as f1:\n",
    "                for line in f1:\n",
    "                    self.labels.append(int(line.strip()))\n",
    "            assert len(self.labels) == len(self.documents)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence = self.documents[index].split()\n",
    "        if len(sequence) > self.max_len - 1:\n",
    "            sequence = sequence[: self.max_len - 1]\n",
    "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
    "            self.token2ind[word] if word in self.token2ind else self.token2ind[\"<oov>\"]\n",
    "            for word in sequence[: self.max_len]\n",
    "        ]#fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
    "        \n",
    "        if self.task == \"language_modeling\":\n",
    "            target = source_sequence[1:]\n",
    "            target.append(self.token2ind[\"<eos>\"])\n",
    "        elif self.task == \"classification\":\n",
    "            target = [self.labels[index]]\n",
    "        sample = {\n",
    "            \"source_sequence\": torch.tensor(source_sequence),\n",
    "            \"target\": torch.tensor(target),\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "def MyCollator(batch):\n",
    "    source_sequences = pad_sequence(\n",
    "        #we use padding to match the length of the sequences in the same batch\n",
    "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
    "    )\n",
    "    target = pad_sequence(\n",
    "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
    "    )\n",
    "    return source_sequences, target.reshape(-1)\n",
    "\n",
    "\n",
    "def get_loader(\n",
    "    path_documents,\n",
    "    path_labels=None,\n",
    "    token2ind={},\n",
    "    max_len=512,\n",
    "    batch_size=32,\n",
    "    task=\"language_modeling\",\n",
    "):\n",
    "    dataset = Dataset(\n",
    "        path_documents,\n",
    "        path_labels=path_labels,\n",
    "        token2ind=token2ind,\n",
    "        max_len=512,\n",
    "        task=task,\n",
    "    )\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=MyCollator,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTns4lHrjUTa"
   },
   "source": [
    "## The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4_jwosiLjRsS"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    path_data_train,\n",
    "    path_labels_train=None,\n",
    "    path_data_valid=None,\n",
    "    save_interval=-1,\n",
    "    log_interval=5,\n",
    "    task=\"language_modeling\",\n",
    "    batch_size=32,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    ntokens = len(token2ind)\n",
    "    data_loader = get_loader(\n",
    "        path_data_train,\n",
    "        path_labels_train,\n",
    "        token2ind,\n",
    "        task=task,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    losses = []\n",
    "    for idx, data in enumerate(data_loader): #step 1\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
    "            device\n",
    "        )\n",
    "        input = data[0].to(device)\n",
    "        output = model(input, src_mask) #step 2\n",
    "        if task == 'classification':\n",
    "            #last vector only\n",
    "            output = output[-1] #fill me \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = data[1]#fill me\n",
    "        target = target.to(device)\n",
    "        loss = criterion(output, target)#fill me, Cross entropy check next cells\n",
    "        #fill me step 3\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
    "        #fill me step 4\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
    "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
    "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
    "                )\n",
    "            )\n",
    "            losses.append(cur_loss)\n",
    "            total_loss = 0\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pgf6BDB9jUr6"
   },
   "outputs": [],
   "source": [
    "ntokens = len(ind2token)#fill me # the size of vocabulary\n",
    "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # the number of heads in the multiheadattention models\n",
    "dropout = 0  # the dropout value\n",
    "\n",
    "nclasses = 2 # for classification task only\n",
    "\n",
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "u-OLy4KIkDwf"
   },
   "outputs": [],
   "source": [
    "# optimization paramerters\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
    "lr = 0.0003  # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bwh3n9xZQy4e",
    "outputId": "0e9bd8f6-357d-47af-8818-c10c72fe1d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 17:56:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10146460 (9.7M) [text/plain]\n",
      "Saving to: ‘pretraining_subset.txt.1’\n",
      "\n",
      "\r",
      "pretraining_subset.   0%[                    ]       0  --.-KB/s               \r",
      "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-11-30 17:56:20 (93.4 MB/s) - ‘pretraining_subset.txt.1’ saved [10146460/10146460]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
    "path_data_train = \"pretraining_subset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0m11g4ScjZaR",
    "outputId": "7930171c-4b6e-476b-96cc-9fa892f2a36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 3125 steps | loss 7.30024 | ppl 1480.652\n",
      "| epoch   1 |  1000/ 3125 steps | loss 6.46960 | ppl  645.228\n",
      "| epoch   1 |  1500/ 3125 steps | loss 6.22684 | ppl  506.155\n",
      "| epoch   1 |  2000/ 3125 steps | loss 6.05449 | ppl  426.020\n",
      "| epoch   1 |  2500/ 3125 steps | loss 5.91089 | ppl  369.034\n",
      "| epoch   1 |  3000/ 3125 steps | loss 5.83163 | ppl  340.913\n",
      "| epoch   2 |   500/ 3125 steps | loss 5.51998 | ppl  249.631\n",
      "| epoch   2 |  1000/ 3125 steps | loss 5.46913 | ppl  237.253\n",
      "| epoch   2 |  1500/ 3125 steps | loss 5.43575 | ppl  229.466\n",
      "| epoch   2 |  2000/ 3125 steps | loss 5.40896 | ppl  223.399\n",
      "| epoch   2 |  2500/ 3125 steps | loss 5.38684 | ppl  218.511\n",
      "| epoch   2 |  3000/ 3125 steps | loss 5.35690 | ppl  212.067\n"
     ]
    }
   ],
   "source": [
    "#pretraining on a tiny subset\n",
    "log_interval = 500\n",
    "epochs = 2\n",
    "for epoch in range(1, epochs + 1): #5\n",
    "    train(\n",
    "        path_data_train,\n",
    "        save_interval=-1,\n",
    "        task=\"language_modeling\", # fill me\n",
    "        batch_size=16,\n",
    "        log_interval=log_interval,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeOM1dOvkO4e"
   },
   "source": [
    "## Text Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BcBC6FSkMH3",
    "outputId": "65053a94-ea63-4e4a-9d9c-a8585a5d6724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 18:10:58--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88093955 (84M) [application/octet-stream]\n",
      "Saving to: ‘pretrained_model_4layers.pt’\n",
      "\n",
      "pretrained_model_4l 100%[===================>]  84.01M   172MB/s    in 0.5s    \n",
      "\n",
      "2021-11-30 18:11:16 (172 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
    "\n",
    "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
    "\n",
    "#load the checkpoint\n",
    "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
    "#load state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBRRVsWqlIoQ",
    "outputId": "ee3b97e3-f878-428d-8d82-33884f57fb26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 12.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 9.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 51 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61 kB 4.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71 kB 4.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 81 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 92 kB 4.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 102 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 122 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 133 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 143 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 163 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 174 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 184 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 194 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 204 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 215 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 225 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 235 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 245 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 256 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 266 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 276 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 286 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 296 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 307 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 317 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 327 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 337 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 348 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 358 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 368 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 378 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 389 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 399 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 409 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 419 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 430 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 440 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 450 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 460 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 471 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 481 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 491 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 501 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 512 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 522 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 532 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 542 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 552 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 563 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 573 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 583 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 593 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 604 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 614 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 624 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 634 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 645 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 655 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 665 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 675 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 686 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 696 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 706 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 716 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 727 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 737 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 747 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 757 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 768 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 778 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 788 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 798 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 808 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 819 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 829 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 839 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 849 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 860 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 870 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 880 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 890 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 901 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 911 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 921 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 931 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 942 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 952 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 962 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 972 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 983 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 993 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.0 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.0 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.0 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.0 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.0 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2 MB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "--2021-11-30 18:11:22--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115362 (1.1M) [application/octet-stream]\n",
      "Saving to: ‘sentencepiece.french.model’\n",
      "\n",
      "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2021-11-30 18:11:22 (20.9 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
      "\n",
      "['▁Bonjour', '▁les', '▁amis', '!']\n",
      "Bonjour les amis!\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
    "\n",
    "#examples\n",
    "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
    "decoded = s.decode_pieces(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TtLlV05pkQI3"
   },
   "outputs": [],
   "source": [
    "def infer_next_token(sent):\n",
    "    model.eval()\n",
    "    sent_pieces = s.encode_as_pieces(sent)\n",
    "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
    "    source = torch.tensor(source).to(device)\n",
    "    source = source.reshape(-1, 1)\n",
    "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
    "    out = model(source, src_mask)\n",
    "    next_token_ind = out[-1].argmax(-1) #fill me\n",
    "    return next_token_ind, out\n",
    "    \n",
    "def infer_next_tokens(sent, max_len=50):\n",
    "    # to be implemented\n",
    "    max_len -= len(sent.split(' '))\n",
    "    current_sentence, i = sent, 0\n",
    "    while i < max_len:\n",
    "        next_token_ind, _ = infer_next_token(current_sentence)\n",
    "        encoded_next_word = ind2token[next_token_ind.item()]\n",
    "        decoded_next_word = s.decode_pieces([encoded_next_word])\n",
    "        if decoded_next_word == \"<eos>\":\n",
    "            break\n",
    "        current_sentence += ' ' + decoded_next_word\n",
    "        i += 1\n",
    "    return current_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "f83Nn5nSly4v",
    "outputId": "c95e1586-3782-4a12-c042-d7753654756e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Bonjour les gens qui ont été très accueillants et sympathiques .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Bonjour les\"\n",
    "infer_next_tokens(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7mjVzomoZ3"
   },
   "source": [
    "### Supervised task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0K1BZsblmEmx",
    "outputId": "e202c133-bcfa-486e-a3ea-882505d5ed8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 18:11:22--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1495960 (1.4M) [text/plain]\n",
      "Saving to: ‘train.review.spm’\n",
      "\n",
      "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2021-11-30 18:11:23 (26.3 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
      "\n",
      "--2021-11-30 18:11:23--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3200 (3.1K) [text/plain]\n",
      "Saving to: ‘train.label’\n",
      "\n",
      "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-30 18:11:23 (31.9 MB/s) - ‘train.label’ saved [3200/3200]\n",
      "\n",
      "--2021-11-30 18:11:23--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1864544 (1.8M) [text/plain]\n",
      "Saving to: ‘test.review.spm’\n",
      "\n",
      "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2021-11-30 18:11:27 (31.4 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
      "\n",
      "--2021-11-30 18:11:27--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4000 (3.9K) [text/plain]\n",
      "Saving to: ‘test.label’\n",
      "\n",
      "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-30 18:11:28 (32.6 MB/s) - ‘test.label’ saved [4000/4000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
    "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
    "\n",
    "path_data_train = \"train.review.spm\"\n",
    "path_labels_train = \"train.label\"\n",
    "\n",
    "path_data_valid = \"test.review.spm\"\n",
    "path_labels_valid = \"test.label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_MLfvjiom2SL"
   },
   "outputs": [],
   "source": [
    "# a function to evaluate the validation accuracy of the model.\n",
    "def evaluate_accuracy(data_loader):\n",
    "    #to be implemented\n",
    "    model.eval()\n",
    "    total_correct_predictions = total_length = 0\n",
    "    for idx, (input_data, target_data) in enumerate(data_loader):\n",
    "        src_mask = model.base.generate_square_subsequent_mask(\n",
    "            input_data.size(0)\n",
    "        ).to(device)\n",
    "        input_data = input_data.to(device)\n",
    "        output = model(input_data, src_mask)\n",
    "        output = output[-1]\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        max_prob_indices = output.argmax(-1)\n",
    "        target_data = target_data.to(device)\n",
    "        total_length += target_data.shape[0]\n",
    "        correct_predictions = torch.sum(target_data == max_prob_indices)\n",
    "        total_correct_predictions += correct_predictions.item()\n",
    "    return total_correct_predictions / total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qzmx7T7xoa6v"
   },
   "outputs": [],
   "source": [
    "#save the base model to be loaded later in the fine-tuning phase\n",
    "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-xclMCpnVpw",
    "outputId": "a055c395-f2bc-484c-da31-5019b6e6ad31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Trainig FROM SCRATCH======\n",
      "| epoch   1 |    50/  200 steps | loss 0.74922 | ppl    2.115\n",
      "| epoch   1 |   100/  200 steps | loss 0.75825 | ppl    2.135\n",
      "| epoch   1 |   150/  200 steps | loss 0.72614 | ppl    2.067\n",
      "| epoch   2 |    50/  200 steps | loss 0.62177 | ppl    1.862\n",
      "| epoch   2 |   100/  200 steps | loss 0.61035 | ppl    1.841\n",
      "| epoch   2 |   150/  200 steps | loss 0.56130 | ppl    1.753\n",
      "| epoch   3 |    50/  200 steps | loss 0.31186 | ppl    1.366\n",
      "| epoch   3 |   100/  200 steps | loss 0.29505 | ppl    1.343\n",
      "| epoch   3 |   150/  200 steps | loss 0.30289 | ppl    1.354\n",
      "| epoch   4 |    50/  200 steps | loss 0.22074 | ppl    1.247\n",
      "| epoch   4 |   100/  200 steps | loss 0.10501 | ppl    1.111\n",
      "| epoch   4 |   150/  200 steps | loss 0.12137 | ppl    1.129\n",
      "| epoch   5 |    50/  200 steps | loss 0.02225 | ppl    1.023\n",
      "| epoch   5 |   100/  200 steps | loss 0.06327 | ppl    1.065\n",
      "| epoch   5 |   150/  200 steps | loss 0.00181 | ppl    1.002\n",
      "| epoch   6 |    50/  200 steps | loss 0.01192 | ppl    1.012\n",
      "| epoch   6 |   100/  200 steps | loss 0.00312 | ppl    1.003\n",
      "| epoch   6 |   150/  200 steps | loss 0.03836 | ppl    1.039\n",
      "| epoch   7 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
      "| epoch   7 |   100/  200 steps | loss 0.00003 | ppl    1.000\n",
      "| epoch   7 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
      "| epoch   8 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
      "| epoch   8 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
      "| epoch   8 |   150/  200 steps | loss 0.00002 | ppl    1.000\n",
      "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  12 |    50/  200 steps | loss 0.00008 | ppl    1.000\n",
      "| epoch  12 |   100/  200 steps | loss 0.00005 | ppl    1.000\n",
      "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  13 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  13 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  13 |   150/  200 steps | loss 0.00898 | ppl    1.009\n",
      "| epoch  14 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  15 |    50/  200 steps | loss 0.02151 | ppl    1.022\n",
      "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  15 |   150/  200 steps | loss 0.00853 | ppl    1.009\n",
      "\n",
      "=====PRETRAINED MODEL======\n",
      "| epoch   1 |    50/  200 steps | loss 0.80905 | ppl    2.246\n",
      "| epoch   1 |   100/  200 steps | loss 0.67960 | ppl    1.973\n",
      "| epoch   1 |   150/  200 steps | loss 0.59737 | ppl    1.817\n",
      "| epoch   2 |    50/  200 steps | loss 0.49648 | ppl    1.643\n",
      "| epoch   2 |   100/  200 steps | loss 0.47425 | ppl    1.607\n",
      "| epoch   2 |   150/  200 steps | loss 0.46735 | ppl    1.596\n",
      "| epoch   3 |    50/  200 steps | loss 0.31952 | ppl    1.376\n",
      "| epoch   3 |   100/  200 steps | loss 0.39508 | ppl    1.485\n",
      "| epoch   3 |   150/  200 steps | loss 0.40738 | ppl    1.503\n",
      "| epoch   4 |    50/  200 steps | loss 0.25752 | ppl    1.294\n",
      "| epoch   4 |   100/  200 steps | loss 0.27583 | ppl    1.318\n",
      "| epoch   4 |   150/  200 steps | loss 0.30909 | ppl    1.362\n",
      "| epoch   5 |    50/  200 steps | loss 0.13183 | ppl    1.141\n",
      "| epoch   5 |   100/  200 steps | loss 0.18262 | ppl    1.200\n",
      "| epoch   5 |   150/  200 steps | loss 0.29313 | ppl    1.341\n",
      "| epoch   6 |    50/  200 steps | loss 0.09421 | ppl    1.099\n",
      "| epoch   6 |   100/  200 steps | loss 0.13840 | ppl    1.148\n",
      "| epoch   6 |   150/  200 steps | loss 0.09388 | ppl    1.098\n",
      "| epoch   7 |    50/  200 steps | loss 0.03640 | ppl    1.037\n",
      "| epoch   7 |   100/  200 steps | loss 0.14594 | ppl    1.157\n",
      "| epoch   7 |   150/  200 steps | loss 0.09273 | ppl    1.097\n",
      "| epoch   8 |    50/  200 steps | loss 0.01309 | ppl    1.013\n",
      "| epoch   8 |   100/  200 steps | loss 0.03236 | ppl    1.033\n",
      "| epoch   8 |   150/  200 steps | loss 0.02182 | ppl    1.022\n",
      "| epoch   9 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
      "| epoch   9 |   100/  200 steps | loss 0.03036 | ppl    1.031\n",
      "| epoch   9 |   150/  200 steps | loss 0.01517 | ppl    1.015\n",
      "| epoch  10 |    50/  200 steps | loss 0.01044 | ppl    1.010\n",
      "| epoch  10 |   100/  200 steps | loss 0.00398 | ppl    1.004\n",
      "| epoch  10 |   150/  200 steps | loss 0.00004 | ppl    1.000\n",
      "| epoch  11 |    50/  200 steps | loss 0.00004 | ppl    1.000\n",
      "| epoch  11 |   100/  200 steps | loss 0.00106 | ppl    1.001\n",
      "| epoch  11 |   150/  200 steps | loss 0.00586 | ppl    1.006\n",
      "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  12 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  13 |    50/  200 steps | loss 0.00006 | ppl    1.000\n",
      "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  13 |   150/  200 steps | loss 0.01057 | ppl    1.011\n",
      "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
      "| epoch  14 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
      "| epoch  15 |    50/  200 steps | loss 0.01146 | ppl    1.012\n",
      "| epoch  15 |   100/  200 steps | loss 0.00033 | ppl    1.000\n",
      "| epoch  15 |   150/  200 steps | loss 0.02272 | ppl    1.023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from_scratch_settings = [True, False]\n",
    "\n",
    "from_scratch_valid_acc = []\n",
    "pretrained_valid_acc = []\n",
    "lr = 0.0001\n",
    "\n",
    "for from_scratch in from_scratch_settings:\n",
    "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if not from_scratch:\n",
    "        print(\"=====PRETRAINED MODEL======\")\n",
    "        #load checkpoint\n",
    "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
    "        #load state dict\n",
    "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        print(\"=====Trainig FROM SCRATCH======\")\n",
    "    epochs = 15\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(\n",
    "            path_data_train,\n",
    "            path_labels_train,\n",
    "            save_interval=-1,\n",
    "            task='classification',\n",
    "            batch_size=8,\n",
    "            log_interval=50,\n",
    "        )\n",
    "        acc = evaluate_accuracy(\n",
    "            get_loader(\n",
    "                path_data_valid,\n",
    "                path_labels_valid,\n",
    "                token2ind=token2ind,\n",
    "                batch_size=20,\n",
    "                task='classification',\n",
    "            )\n",
    "        )\n",
    "        if from_scratch:\n",
    "            from_scratch_valid_acc.append(acc)\n",
    "        else:\n",
    "            pretrained_valid_acc.append(acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "RCpBIdTHojm6",
    "outputId": "7665ee4b-47ee-4f59-bd72-462b91a13833"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzV8/7A8de7qbRqj1RaaC8zaVoYKqXkihQhXELh/ohCZLvCtdx0ryzd3KibCIUbcW2VRpZoUzktihYmqWnVMNUs798fnzPTmenMzJmaM99z5ryfj8d5nDnf813ep2a+7/PZRVUxxhhj8ivndQDGGGMikyUIY4wxQVmCMMYYE5QlCGOMMUFZgjDGGBNUea8DKCl169bVpk2beh2GMcZElWXLlu1U1XrB3iszCaJp06YsXbrU6zCMMSaqiMiWgt6zKiZjjDFBWYIwxhgTlCUIY4wxQVmCMMYYE5QlCGOMMUFZgjDGGBOUJQhjjDFBWYIwYbNxIzzzDHz1Fdis8sZEnzIzUM5EhvR0+O9/YcoUWLDg8PbWreGGG+Caa6B+fe/iM8aEzkoQpkQsXw633AInnQRXXw2bN8Ojj8K6dS5Z1K4No0dDw4YwaBD873+Qmel11MaYwlgJwhy1PXtgxgyXAFasgOOOg0sucSWFnj2hnP/rR6tWcP31sHat23f6dJg92yWToUPde6ec4uUnMcYEYyUIUyzZ2TB/Plx5JTRoACNGgAg8/zxs2+YSRq9eh5NDoDZtYPx4SEmBt9+GhAR48kk49VQ45xx49VVXRWWMiQxSVtakTkxMVJusL3xSUmDaNJg6FTZtgpo14aqrXGmhY8djO+/LL7vzbtwINWq45DNsGJx+eomFb4wpgIgsU9XEoO9ZgjAFOXQI3nvPVQt9/LErPfTq5ZLCwIFQuXLJXSs7Gz77zF3r7bfhwAFXwrj+epeIatcuuWsZYw6zBGGKZc0ad6N+5RVITXUNyzltBc2bh//6e/bA66/DSy/Bt9+6to2BA11iKqj6KhSHDsHu3YU/0tOhQgUoX75kn1u0cP+OJraoura32bPdY+tWuPtu16GjYkWvo3MsQZgi7dnjvrlPmQJff+1ubBdd5G7K550HcXHexPXtty6mGTNg715o2tQlqksucb2girrhBz5+/73g65Qr50oplSu782ZkHPmcnX1sn+WUU6BHj8OPJk2O7XwmMmVnw5Ilh5PC+vVue9eu7vcrOdm1uz31FAwY4NrwvORZghCRfsAzQBzwkqo+me/9k4GXgZr+fcao6gf+9+4FbgCygNtU9ePCrmUJomCqLgFs3gxbtgR/3rvX7dumjUsKf/5zZI1XSE93f2xTpsCnnxa8X4UKUKeOu9kX51G9etElk+xslywKSiD5n3N+PngQVq1yVWgLF7r/C3AJIjBhNG/u/c3CHJ2MDPf/O3s2vPuuKymUL+968w0c6BJBw4bub/Gjj+DOO13JokcP+Oc/vW1v8yRBiEgcsB7oA6QAS4AhqromYJ/JwLeqOklE2gIfqGpT/8+vA12Ak4B5QEtVzSroerGcIFRdVVBhCSAtLe8x1aq5b+NNmhx+Puss6NYt8m9SGze6P8bjjz/yRl+lSmTHn50NPp+LP+exc6d7r2HDvAmjZcvI/iyx7o8/4JNP3MDQ9993ib9yZejXzyWF/v2hVq3gx2Zmwosvwl//Crt2uQGkjz3mTTWkVwniDGCsqp7nf30vgKo+EbDPv4GNqvp3//7/UNUz8+8rIh/7z7WooOvFSoL46Sd47TV3089JAFu2HNk9tGbNvDf/wOemTd0vrt18vJdTRx2YMH791b134onQvfvhhNG2bWT9n2Vmut+7UB8VKrhSaf36cMIJ7rkkOzqUhj17XDKYPduVBNLT3d/ShRe6pNC3r/uSEqp9++Dxx2HCBFfiGD3aPapWDd9nyM+rBHEp0E9Vh/lf/xnoqqq3BuzTAPgEqAVUBc5V1WUi8jzwtaq+6t9vCvChqr6V7xo3AjcCnHzyyZ22bClwadUyIS3NdSn94QeoW7fgBNCkiesuaqKPKmzY4BJFcrJ73rrVvVe3bt6E0aHD4WoxVVeVVZwb9rE+SmIkfPXqeRNGYc81a3qTIH/5Bd55xyWF5GT3uRs2hIsvdkmhe3eX/I7Fpk0wZgzMmuUGkD72mCtVHG2HjOKI5ARxhz+Gf/hLEFOA9sCzhJAgAsVCCeL6691YhE8/dXWbpuxTPVyllvPI+R50/PHuxvTHH65b8NH+KcfFuW/yRT2qVAltv4IeGRmwYwds317w8/btrsot2GcJLIEEJo+qVUPrSVacXmfp6fDhhy4pfPONu36rVi4hDBwIiYnhuXl/+SXccQcsXuy+DP7zn+H/Wy8sQYRzqo2tQOOA14382wLdAPQDUNVFIlIJqBvisTFl5kz4z3/ggQcsOcQSEdf76ZRT3BcEcAnis8/cTQSO/oZdqZJ7PtZvv8URSs+trCyXJIpKJmvXuueDB8MXb2Ki+zY/cKDrwBFuSUmwaBG88YYrUZxzjiupjBvnukqXtnCWIMrjGql7427uS4ArVXV1wD4fAjNVdZqItAHmAw2BtsBrHG6kng+0iNVG6s2b3aCxtm1dL5jyNoOWMbmK27sslGcROPtsaNy46OuHS3o6PP00PPGEKyHeeis8+GDJDxr1spvrn4AJuC6sU1X1MRF5BFiqqnP8vZVeBKoBCtytqp/4j70fuB7IBEaq6oeFXausJojMTFdiWLUKVq6EZs28jsgYU5p+/dX1dpoyxbUtPvQQ/OUvJTfQzgbKRbGHH4axY91AsSuv9DoaY4xXVq1y4yfmzXPVTU895QazHmvDfWEJwmZzjWBffAGPPOIGrVlyMCa2nXaaG3fxv/+5jgUXX+ymnlm+PHzXtAQRofbudZPUNW0KEyd6HY0xJhKIwJ/+5EoTEye6QZeJiW7243BUBlmCiECqcNNNrv/166+7vuLGGJOjQgX4v/9zY2buuit8MwhYf5gI9PLLbsDM449Dly5eR2OMiVQ1a7ousOFiJYgIs369687Ws6ebFtgYY7xiCSKCHDrkGqOPO86txeDVFNvGGANWxRRRHnwQli1zs0M2auR1NMaYWGcliAgxb56rS7zpJjes3xhjvGYJIgKkprqZG9u0cZNzGWNMJLAqJo+puhXcdu1ys0cWZy55Y4wJJ0sQHps0Cd57zy0YEh/vdTTGGHOYVTF5yOdzc6ucfz7cdpvX0RhjTF6WIDySng5DhrjZGf/zn8haStIYY8CqmDxz992uBPHhh25lLGOMiTRWgvDA++/D88/DqFHQr5/X0RhjTHCWIErZtm1w3XWuQfqJJ7yOxhhjCmYJohRlZ7vxDr//7mZpPe44ryMyxpiCWRtEKfrnP92I6cmTS2cBdGOMORZWgigly5bBfffBoEFucQ9jjIl0liBKQVqa69J6wgnw4ovWpdUYEx2siqkU3H47/PADLFgAtWt7HY0xxoTGShBhNmsWTJ3qqpd69PA6GmOMCZ0liDDasgVuvBG6doWHHvI6GmOMKR6rYiphqq7NYccOGDrUdW197TW3yLiJQHv2QHKy6142bx4cPAj9+7tFObp3t/84E9MsQYQgK8tNx71jB2zfXvjzjh1unqUcr7wCzZt7F7vJ58AB+PJLlwzmz3fdy7KzoWpVlxAqVnR1ghMnugajCy90yaJvX6hc2evojSlVMZ8g0tPh008Lv/Hv3OnuIfnFxUH9+q53Uv360Lp13tetWkG3bqX/mUyArCxYvvxwQvjiC1dKKF/e/ec8+CCcey506eKSA7iRjJ98ArNnw7vvwssvu4U6+vVzyaJ/f6hZ09vPZUwpEFX1OoYSkZiYqEuXLi32camp7maeo2rVwzf4op5r1YJy1ooTWVRh/XqXDObNc13H9u5173Xo4JLBuefC2WdD9epFny8jw1VBzZ4N77zj5kopXx7OOccliwED4KSTwvqRjAknEVmmqolB34v1BJGdDUuWuBt+/fouQZgos23b4YQwfz6kpLjtTZq4ZNC7N/TqdezT5mZnw+LFLlnMng0bNrjt3bq5ZDFwILRocWzXMKaUWYIwZcv+/a5kkJMU1qxx2+vUcYmgd2+XGJo3D9+oRFV33ZxksXy5296u3eFk0bFj7IyKVHV1sZs3u+57wZ5PPNF15xsyxIreEcSzBCEi/YBngDjgJVV9Mt/7TwPn+F9WAeqrak3/e1nAd/73flLViwq7liWIMkwVVq2Cjz5yjy++gMxM12jcvfvhhBAf792NZ8sWVwU1ezZ8/rkrbTRpAhdf7JJF+/Yu3kqVovPmmJ3tGuQKSgBbtsAff+Q9pkYNaNrU/Ts0aQILF8LKla6q77HHXFtOrCTQCOZJghCROGA90AdIAZYAQ1R1TQH7jwA6qur1/tdpqlot1OtZgihjdu+GuXMPJ4Vff3XbExJcY/F558EZZ0TmlLipqW6h8dmz3Wc4eDDv+8cd55JFzqNSpbyvi/MIR7JJT4effsp789+yBQ4dyrtfnTruxt+06eFEEJgQ8jfkZ2e7kaMPPuimFjjzTHj8cRtB6jGvEsQZwFhVPc//+l4AVQ26CoKIfAU8pKpz/a8tQZSWvXth2jQ3gKNNG9cdq0WLw716SkNWFixdejghLF7sbii1a7supv36uecGDUovppKwf79LElu3uhvvsTyCdaULpxNOyHvTz/9cLeQ/z7wyMtw6uw8/DL/84pL944/D6aeXYPAmVF4liEuBfqo6zP/6z0BXVb01yL5NgK+BRqqa5d+WCawAMoEnVfWdIMfdCNwIcPLJJ3fasmVLWD5LmfXTTzBhgptBMC0t73txcXDKKS5Z5CSNnOcaNUrm+r/+Ch9/7BLCJ5+4UoOI63Larx+cfz4kJrpYYp2qu7HmTxrh+PutWBEaNQr/uI/0dLe04pNPuv/7yy6DRx+Fli3De12TRzQkiHtwyWFEwLaGqrpVRJoDnwK9VfXHgq5nJYhiWLkSnnoKZs50N5jLL4e77nKlhu+/h3XrYO3aw88bNribU44GDYInjoYNC69TzsiAr746XEpYscJtP+EElxD69YM+fVzVhYkd+/bB+PHw9NNuION118Ff/wqNG3sdWUyI+ComEfkWuEVVvyrgXNOA91X1rYKuZwmiCKqu189TT7lv61WrwvDhMHKkqy4oTGYmbNx4OGEEJo/ffju8X/XqLlEEJo0mTVzV0Ycfuuvv3+/GESQlHU4Kp50WnQ23pmRt3+6qml54wX3RuOUWuPdeqFvX68jKNK8SRHlcI3VvYCuukfpKVV2db7/WwEdAM/UHIyK1gD9U9aCI1AUWAQMKauAGSxAFysiAN990iWHFCtfV8Lbb4Oab3Ui/Y6HqqokCE0bO89atefc9+WRXZdSvn+uKevzxx3ZtU3Zt2QJjx8L06e6LzJ13wh13hDaw0RSbl91c/wRMwHVznaqqj4nII8BSVZ3j32csUElVxwQcdybwbyAbN+PsBFWdUti1LEHkk5YGL73kiu0//eS+zd91F1x9den0/Nm/3yWLTZtcCaFVK+vSaIpnzRp44AHXG6xuXTdn/l/+4np9mRJjA+Viya+/wrPPwqRJrnfS2WfD6NFwwQVWjWOi0+LFcP/9blBk48ZusN2117qqSnPMCksQdscoK9atc4tdN2nieoX07g1ff+0GJ114oSUHE726dHFdhefNcx0khg1zAw/feis8vbhMLrtrRDNVN6p4wADXKDxjBtxwg5us7q233EpFxpQVOV96/vtf1/V58GDo3NlNu2LCwhJENMrKcn8kZ57pqpC+/NIVu3/6Cf71Lzj1VK8jNCY8RNzUJatWucGdqamu08OQIUd2jDDHzBJENMnOdmsTtG4Nl1ziFqx4/nmXGMaOhXr1vI7QmNIRF+faIdatc1+OZs92HSHGjTtyShBz1CxBRIvkZDeqeOhQN5J51ixXlXTLLW4xG2NiUeXK7svRmjWuJHHPPW7SxvnzvY7sSKpuMaooYgki0m3Y4IrU55zj1j197TW3gMXgwTYFhTE5mjeHOXPg/fddCeLcc93UHT//7HVkbnT41KkucVWr5jqSDBwIjzzi4t26NWIb262ba6TavdvNS/P8867f9333uVHPti6yMYU7cMBVNT3xhOu99+CDbqBdaU4+CW5k+KRJ7rFjh5vmfOBA96Vv+XJXA5Bz/61f360fcvrph5/DuZ5JABsHEU0OHXK/UA8/7OaoGTbMfdM41tXQjIk1mza5xPDOO24CwOeeczMCh9vKlW4SzNdeczMZ9O/vvtydc07eG35amtv3229dwli+HFavdlPbgJttoGPHwwnj9NNdO0sJj/+wBBENVF0RefRo9w2jTx/4xz/ctw5jzNH76CMYMcKtQTFokJtd4OSTS/Ya2dnwv/+5cy9Y4NoFr7sObr+9eMvQHjwIPt/hpPHtty6JpKe79ytVclVVgaWN9u2PaXR5YQkCVS0Tj06dOmnUWr5ctWdPVVBt00b1gw9Us7O9jsqYsuPAAdW//U21cmX3eOwxt+1Y7d+v+txzqqee6v5+GzdWHTdOdffuYz93jowM1dWrVV95RfWOO9y9okYNdz1QLV9etX//oz49buqjoPdVK0F46Zdf3BQCL7/sprh++GG48UabQsCYcNmyxVU7/fe/7pv9s8+6CSSP5jzPP+/WUtm3D7p1g1GjXAmlNP5+VV0VWk4po2pV1055FKwEEWnS0lTHjlWtUkW1YkXV0aNV9+zxOipjYsfHH6u2bOm+gV98seqmTUUfk52t+uWXqoMHq8bFuccVV6guWhT2cMOJQkoQ1s21NGVnuymMW7VyfbcvuMBNjT1u3JHr9xpjwqdvXzca+4kn3Poobdq4XoMHDhy5b0YGvPGGKyUkJbl5oe68032Df/11t72MsgRRWj77zM0bc+21cNJJbg6lWbNcVzZjTOk77jgYM8aNxr7wQreKXfv2rrEZXFfzv//d/Y0OGeJmR544EVJS3PYYWPHOEkS4bdjg6iV79nTzxsyY4SYcS0ryOjJjDLgb/axZrmRQoYLrlnrGGW77mDGuxP/++660/3//5+r7Y4QliHA5dMg1hrVr537xHnvMrfd85ZU29bYxkejcc12X0nHj3MC2K65w1VDz5sXseirWiylcpk931UnXXefW2T3xRK8jMsaYIxTWi8n6U4bLypVuWowXX7Q5k4wxUSn2ykylxedzPSMsORhjopQliHDx+VyPCGOMiVKWIMJh9243StoShDEmilmCCIfVq92zJQhjTBSzBBEOPp97tgRhjIliliDCwedzc7k3auR1JMYYc9SKTBAicqGIWCIpjpwG6lJYDcoYY8IllBv/5cAGERknIq3DHVDUU7UeTMaYMqHIBKGqVwMdgR+BaSKySERuFJHqYY8uGv36q+vFZAnCGBPlQqo6UtXfgLeAN4AGwEBguYiMCGNs0ckaqI0xZUQobRAXichsIBmoAHRR1fOBeODO8IYXhSxBGGPKiFBKEJcAT6tqB1V9SlV3AKjqH8ANhR0oIv1E5HsR+UFExgR5/2kRWeF/rBeRvQHvXSsiG/yPa4v5ubzj80H9+lCvnteRGGPMMQllsr6xwLacFyJSGThBVTer6vyCDhKROGAi0AdIAZaIyBxVXZOzj6qOCth/BK6tAxGpDTwEJAIKLPMfu6cYn80b1kBtjCkjQilBvAlkB7zO8m8rShfgB1XdqKqHcO0XAwrZfwjwuv/n84C5qrrbnxTmAkexsngpy852o6gtQRhjyoBQEkR5/w0eAP/PFUM4riHwc8DrFP+2I4hIE6AZ8GlxjvX3ploqIktTU1NDCCnMtmyB33+3BGGMKRNCSRCpInJRzgsRGQDsLOE4rgDeUtWs4hykqpNVNVFVE+tFQp2/NVAbY8qQUBLEzcB9IvKTiPwM3APcFMJxW4HAVb0b+bcFcwWHq5eKe2zkyEkQ7dp5G4cxxpSAIhupVfVHoJuIVPO/Tgvx3EuAFiLSDHdzvwK4Mv9O/tHZtYBFAZs/Bh4XkVr+132Be0O8rnd8Pjj5ZDcPkzHGRLmQlhwVkQuAdkAl8c8vpKqPFHaMqmaKyK24m30cMFVVV4vII8BSVZ3j3/UK4A0NWBxbVXeLyKO4JAPwiKruLsbn8ob1YDLGlCFFJggReQGoApwDvARcCiwO5eSq+gHwQb5tf833emwBx04FpoZynYiQkQHr1kG/yO9sZYwxoQilDeJMVb0G2KOqDwNnAC3DG1YU+uEHOHTIShDGmDIjlARxwP/8h4icBGTg5mMygawHkzGmjAmlDeI9EakJPAUsx41sfjGsUUUjnw/KlYPWNiO6MaZsKDRB+BcKmq+qe4G3ReR9oJKq7iuV6KKJzwenngqVK3sdiTHGlIhCq5hUNRs3n1LO64OWHApgPZiMMWVMKG0Q80XkEhFbP7NA6emukdoShDGmDAklQdyEm5zvoIj8JiL7ReS3MMcVXdatcxP1WYIwxpQhoYyktqVFi2I9mIwxZVAoA+W6B9uuqgtLPpwo5fNBxYqukdoYY8qIULq5jg74uRJunYdlQK+wRBSNVq923VsrVPA6EmOMKTGhVDFdGPhaRBoDE8IWUTTy+SApyesojDGmRIXSSJ1fCtCmpAOJWr/95hYKsvYHY0wZE0obxHO40dPgEkoCbkS1AVjjX2LbEoQxpowJpQ1iacDPmcDrqvplmOKJPtaDyRhTRoWSIN4CDuQsByoicSJSRVX/CG9oUcLng6pVoUkTryMxxpgSFdJIaiBwgqHKwLzwhBOFfD63xGi5o2nOMcaYyBXKXa1S4DKj/p+rhC+kKGNzMBljyqhQEsTvInJ6zgsR6QSkhy+kKJKaCtu3uxKEMcaUMaG0QYwE3hSRXwABTgQuD2tU0WL1avdsJQhjTBkUykC5JSLSGmjl3/S9qmaEN6woYT2YjDFlWJFVTCJyC1BVVX2q6gOqicj/hT+0KODzQa1a0MBWYDXGlD2htEEM968oB4Cq7gGGhy+kKJLTQG1LZRhjyqBQEkRc4GJBIhIHVAxfSFFC1XowGWPKtFAaqT8CZorIv/2vbwI+DF9IUWLrVti3zxKEMabMCiVB3APcCNzsf70K15MptlkDtTGmjCuyiklVs4FvgM24tSB6AWvDG1YUyEkQNgbCGFNGFViCEJGWwBD/YycwE0BVzymd0CKcz+d6L9Wp43UkxhgTFoVVMa0DPgf6q+oPACIyqlSiigbWQG2MKeMKq2IaBGwDFojIiyLSGzeS2mRluXUgLEEYY8qwAhOEqr6jqlcArYEFuCk36ovIJBHpG8rJRaSfiHwvIj+IyJgC9rlMRNaIyGoReS1ge5aIrPA/5hTvY4XZpk2Qnm4JwhhTpoUy1cbvwGvAayJSCxiM69n0SWHH+cdLTAT64JYpXSIic1R1TcA+LYB7gSRV3SMi9QNOka6qCcX9QKXCejAZY2JAsRYxUNU9qjpZVXuHsHsX4AdV3aiqh4A3gAH59hkOTPSPzkZVdxQnHs/kJIi2bb2Nwxhjwiicq9w0BH4OeJ3i3xaoJdBSRL4Uka9FpF/Ae5VEZKl/+8VhjLP4fD5o1gyqVfM6EmOMCZtQBsqF+/otgJ5AI2ChiHTwz/3URFW3ikhz4FMR+U5Vfww8WERuxA3i4+STTy69qK0HkzEmBoSzBLEVaBzwupF/W6AUYI6qZqjqJmA9LmGgqlv9zxuBZKBj/gv4q7sSVTWxXr16Jf8Jgjl0CL7/3hKEMabMC2eCWAK0EJFmIlIRuALI3xvpHVzpARGpi6ty2igitUTkuIDtScAaIsH69ZCZaQnCGFPmha2KSVUzReRW4GMgDpiqqqtF5BFgqarO8b/XV0TWAFnAaFXdJSJnAv8WkWxcEnsysPeTp6wHkzEmRoS1DUJVPwA+yLftrwE/K3CH/xG4z1dAh3DGdtR8PoiLg1atit7XGGOiWDirmMomnw9atoTjjvM6EmOMCStLEMVlPZiMMTHCEkRx/P47bNxoCcIYExMsQRTH2rVuqVFLEMaYGGAJojisB5MxJoZYgigOn881Tp9yiteRGGNM2FmCKA6fz03QFxfndSTGGBN2liCKw3owGWNiiCWIUO3ZA1u3WoIwxsQMSxChWr3aPVuCMMbECEsQobIeTMaYGGMJIlQ+H1SvDo0bF72vMcaUAZYgQpXTQC3idSTGGFMqLEGEQtV6MBljYo4liFBs3w67dlmCMMbEFEsQobAeTMaYGGQJIhQ5PZjatfM2DmOMKUWWIELh80HdulC/vteRGGNMqbEEEQrrwWSMiUGWIIpiPZiMMTHKEkRRfvoJ0tIsQRhjYo4liKLYFBvGmBhlCaIo1oPJGBOjLEEUxeeDRo2gZk2vIzHGmFJlCaIo1kBtjIlRliAKk5kJa9dagjDGxCRLEIX58Uc4eNAShDEmJlmCKIz1YDLGxDBLEIXx+dzo6TZtvI7EGGNKnSWIwvh8cMopUKWK15EYY0ypC2uCEJF+IvK9iPwgImMK2OcyEVkjIqtF5LWA7deKyAb/49pwxlkg68FkjIlh5cN1YhGJAyYCfYAUYImIzFHVNQH7tADuBZJUdY+I1Pdvrw08BCQCCizzH7snXPEe4cAB2LABLr201C5pjDGRJJwliC7AD6q6UVUPAW8AA/LtMxyYmHPjV9Ud/u3nAXNVdbf/vblAvzDGeqTvv4esLCtBGGNiVjgTREPg54DXKf5tgVoCLUXkSxH5WkT6FeNYRORGEVkqIktTU1NLMHSsB5MxJuZ53UhdHmgB9ASGAC+KSMhzWqjqZFVNVNXEevXqlWxkPh9UqAAtWpTseY0xJkqEM0FsBRoHvG7k3xYoBZijqhmquglYj0sYoRwbXj4ftGoFFSuW6mWNMSZShDNBLAFaiEgzEakIXAHMybfPO7jSAyJSF1fltBH4GOgrIrVEpBbQ17+t9FgPJmNMjAtbglDVTOBW3I19LTBLVVeLyCMicpF/t4+BXSKyBlgAjFbVXaq6G3gUl2SWAI/4t5WO/fth82ZLEMaYmBa2bq4AqvoB8EG+bX8N+FmBO/yP/MdOBaaGM74CrfH3xLUEYYyJYWFNEFHLejCZUpSRkUFKSgoHDhzwOhRThlWqVIlGjRpRoUKFkLyXPFwAABTeSURBVI+xBBGMzweVK0OzZl5HYmJASkoK1atXp2nTpoiI1+GYMkhV2bVrFykpKTQrxn3N626ukcnnc0uMlrN/HhN+Bw4coE6dOpYcTNiICHXq1Cl2KdXugMFYDyZTyiw5mHA7mt8xSxD57dwJv/5qCcIYE/MsQeS3erV7tgRhYsTevXv517/+lfs6OTmZ/v37H/X5xo4dS8OGDUlISKB9+/bMmZN/+FPhpk2bxi+//FLs677wwgtMnz692McFM3ToUN56660SOVc0swSRn/VgMjEmf4IoCaNGjWLFihW8+eabXH/99WRnZ+d5PzMzs8BjC0sQWVlZBR538803c8011xxdwBGmsH+f0mS9mPLz+aBmTTjpJK8jMTFo5EhYsaJkz5mQABMmFPz+mDFj+PHHH0lISKBPnz5ccMEFpKWlcemll+Lz+ejUqROvvvoqIsKyZcu44447SEtLo27dukybNo0GDRoUeO42bdpQvnx5du7cyWWXXUZCQgJffPEFQ4YMoWfPnkec68svv2Tp0qVcddVVVK5cmUWLFtGmTRsuv/xy5s6dy913383+/fuZPHkyhw4d4tRTT+WVV16hSpUqjB07lmrVqnHXXXfRs2dPunbtyoIFC9i7dy9Tpkzh7LPPJisrizFjxpCcnMzBgwe55ZZbuOmmm1BVRowYwdy5c2ncuDEVC5hi58UXXwx67e3bt3PzzTezceNGACZNmsSZZ57J9OnTGT9+PCLCaaedxiuvvMLQoUPp378/l/qXEqhWrRppaWkkJyfz4IMPUqtWLdatW8f69eu5+OKL+fnnnzlw4AC33347N954IwAfffQR9913H1lZWdStW5e5c+fSqlUrvvrqK+rVq0d2djYtW7Zk0aJFHMs8dZYg8stpoLZGQxMjnnzySXw+Hyv8mSk5OZlvv/2W1atXc9JJJ5GUlMSXX35J165dGTFiBO+++y716tVj5syZ3H///UydWvB41m+++YZy5crl3qQOHTrE0qVLycjIoEePHkHP9fzzzzN+/HgSExNzz1OnTh2WL18OwK5duxg+fDgADzzwAFOmTGHEiBFHXDszM5PFixfzwQcf8PDDDzNv3jymTJlCjRo1WLJkCQcPHiQpKYm+ffvy7bff8v3337NmzRq2b99O27Ztuf76648456BBg4Je+7bbbqNHjx7Mnj2brKws0tLSWL16NX/729/46quvqFu3Lrt3Fz0ZxPLly/H5fLldUadOnUrt2rVJT0+nc+fOXHLJJWRnZzN8+HAWLlxIs2bN2L17N+XKlePqq69mxowZjBw5knnz5hEfH39MyQEsQeSl6hLEFVd4HYmJUYV90y9NXbp0oVGjRgAkJCSwefNmatasic/no0+fPoCr7imo9PD000/z6quvUr16dWbOnJnbg+byyy8H4Pvvvw/5XIHHAfh8Ph544AH27t1LWloa5513XtBjBg0aBECnTp3YvHkzAJ988gmrVq3KbV/Yt28fGzZsYOHChQwZMoS4uDhOOukkevXqFfScBV37008/zW3/iIuLo0aNGkyfPp3BgwdTt25dAGrXrl3g58vRpUuXPOMUnn32WWbPng3Azz//zIYNG0hNTaV79+65++Wc9/rrr2fAgAGMHDmSqVOnct111xV5vaJYggj0yy+wd6+1P5iYd9xxx+X+HBcXR2ZmJqpKu3btWLRoUZHHjxo1irvuuuuI7VWrVgUo1rkCjwPXgPzOO+8QHx/PtGnTSE5OLvQz5MSfc93nnnvuiKTywQcfHHF8MKFeuzDly5fPbZPJzs7m0KFDue8Ffs7k5GTmzZvHokWLqFKlCj179ix0HEPjxo054YQT+PTTT1m8eDEzZswodmz5WSN1IGugNjGoevXq7N+/v8j9WrVqRWpqau5NPSMjg9U5vf6KqbBzFRXP/v37adCgARkZGcW+CZ533nlMmjSJjIwMANavX8/vv/9O9+7dmTlzJllZWWzbto0FCxYU69q9e/dm0qRJgCsN7du3j169evHmm2+ya9cugNwqpqZNm7Js2TIA5syZkxtLfvv27aNWrVpUqVKFdevW8fXXXwPQrVs3Fi5cyKZNm/KcF2DYsGFcffXVDB48mLi4uGL92wRjCSJQToJo187bOIwpRXXq1CEpKYn27dszevToAverWLEib731Fvfccw/x8fEkJCTw1VdfHdU1CzvX0KFDufnmm0lISCA9Pf2IYx999FG6du1KUlISrVu3LtZ1hw0bRtu2bTn99NNp3749N910E5mZmQwcOJAWLVrQtm1brrnmGs4444ygxxd07WeeeYYFCxbQoUMHOnXqxJo1a2jXrh33338/PXr0ID4+njvucHOSDh8+nM8++4z4+HgWLVqUp9QQqF+/fmRmZtKmTRvGjBlDt27dAKhXrx6TJ09m0KBBxMfH56l+u+iii0hLSyuR6iUAcROqRr/ExERdunTpsZ3kuuvgo49g27aSCcqYEKxdu5Y2bdp4HYYpA5YuXcqoUaP4/PPPg74f7HdNRJapamKw/a0NIlDOHEzGGBNlnnzySSZNmlQibQ85rIopR3a2G0Vt7Q/GmCg0ZswYtmzZwllnnVVi57QEkWPTJkhPtwRhjDF+liByWA8mY4zJwxJEjpwE0batt3EYY0yEsASRw+eDJk3g+OO9jsQYYyKCJYgc1kBtYlhcXBwJCQm5j5ypKaJFcnJykWMyNm/eTHv7Gy8W6+YKkJEB69bBn/7kdSTGeKJy5cq5k/Xlp6qoKuU8XoI3MzOT8uWD37KSk5OpVq0aZ555ZilHdfQi5d+1MJEbWWnasMElCft2Ybw2ciT07Fmyj5Ejix3G5s2badWqFddccw3t27fn559/ZvTo0bRv354OHTowc+ZMwN2Ye/TowYABA2jevDljxoxhxowZdOnShQ4dOvDjjz8ece7PPvsst6TSsWPH3Gk1/v73v9OhQwfi4+MZM2YMAD179mTkyJEkJibyzDPP8N5779G1a1c6duzIueeey/bt29m8eTMvvPACTz/9NAkJCXz++eds376dgQMHEh8fT3x8fG7pIisri+HDh9OuXTv69u0bdKR2sGsAuSOUO3TowGmnncbbb78NuKm3Tz/9dOLj4+nduzfgFk0aP3587jnbt2/P5s2bg/67/uUvfyExMZF27drx0EMP5R6zZMkSzjzzTOLj4+nSpQv79++ne/fueRL5WWedxcqVK4v9/xsqK0GA9WAyMS89PZ2EhAQAmjVrxtNPP82GDRt4+eWX6datG2+//TYrVqxg5cqV7Ny5k86dO9O9e3cAVq5cydq1a6lduzbNmzdn2LBhLF68mGeeeYbnnnuOCfmmqB0/fjwTJ04kKSmJtLQ0KlWqxIcffsi7777LN998Q5UqVfLML5QzRTjAnj17+PrrrxERXnrpJcaNG8c//vEPbr755ty1IMDN/pp/+u09e/awYcMGXn/9dV588UUuu+wy3n77ba6++uo88Z111llBr/Hoo49So0YNvvvuu9xYUlNTj5h6uyiB/64Ajz32GLVr1yYrK4vevXuzatUqWrduzeWXX87MmTPp3Lkzv/32G5UrV+aGG25g2rRpTJgwgfXr13PgwAHi4+OP5r88JJYgwCWIcuWgmPO6GFPiPJrvO38V0+bNm2nSpEnuTSxnkZ+4uDhOOOEEevTowZIlSzj++OPp3Llz7lTdp5xyCn379gWgQ4cOQSe9S0pK4o477uCqq65i0KBBNGrUiHnz5nHddddRpUoVIO/U2IFzDaWkpHD55Zezbds2Dh06lGdq7EDBpt/es2cPzZo1y02EgdOAByroGvPmzeONN97I3a9WrVq89957QafeLkzgvyvArFmzmDx5MpmZmWzbto01a9YgIjRo0IDOnTsDcLy/88zgwYN59NFHeeqpp5g6dSpDhw4t8nrHwqqYwCWIFi2gUiWvIzEmYhQ0iVx+gVODlytXLvd1uXLlgi6dOWbMGF566SXS09NJSkpi3bp1IccxYsQIbr31Vr777jv+/e9/Fzr9dVGxBk4DHuhYrwF5p/QG8pwj8PNs2rSJ8ePHM3/+fFatWsUFF1xQ6PWqVKlCnz59ePfdd5k1axZXXXVVsWMrDksQcHgVOWNMUGeffXbudNipqaksXLiQLl26HNW5fvzxRzp06MA999xD586dWbduHX369OE///kPf/zxB0CBVTX79u2jYcOGALz88su52/NPER5s+u1QFXSNPn36MHHixNzXe/bsKXDq7aZNm+augLd8+fLc9/P77bffqFq1KjVq1GD79u18+OGHgJsOfdu2bSxZsgRw04znJLNhw4Zx22230blzZ2rVqhXy5zoaliDS0+GHHyxBGFOIgQMHctpppxEfH0+vXr0YN24cJ5544lGda8KECbRv357TTjuNChUqcP7559OvXz8uuugiEhMTSUhIyNPAG2js2LEMHjyYTp065a7UBnDhhRcye/bs3EbqYNNvh6qgazzwwAPs2bOH9u3bEx8fz4IFCwqcevuSSy5h9+7dtGvXjueff56WLVsGvVZ8fDwdO3akdevWXHnllSQlJQFuOvSZM2cyYsQI4uPj6dOnT27JolOnThx//PElNqV3YWy67x07YNQoN9X3ueeWfGDGFMGm+zbF8csvv9CzZ0/WrVtX7C6yxZ3uO6wlCBHpJyLfi8gPIjImyPtDRSRVRFb4H8MC3ssK2D4nbEHWrw8zZlhyMMZEvOnTp9O1a1cee+yxUhk/EbZeTCISB0wE+gApwBIRmaOq+ct6M1X11iCnSFfVhHDFZ4wx0eaaa67hmmuuKbXrhTMFdQF+UNWNqnoIeAMYEMbrGRO1ykpVr4lcR/M7Fs4E0RD4OeB1in9bfpeIyCoReUtEGgdsryQiS0XkaxG5ONgFRORG/z5LU1NTSzB0Y0pPpUqV2LVrlyUJEzaqyq5du6hUzK78Xg+Uew94XVUPishNwMtAL/97TVR1q4g0Bz4Vke9UNc+4fVWdDEwG10hdmoEbU1IaNWpESkoK9iXHhFOlSpVo1KhRsY4JZ4LYCgSWCBr5t+VS1V0BL18CxgW8t9X/vFFEkoGOwJETuxgT5SpUqFDgiGBjvBTOKqYlQAsRaSYiFYErgDy9kUSkQcDLi4C1/u21ROQ4/891gSQg9I7MxhhjjlnYShCqmikitwIfA3HAVFVdLSKPAEtVdQ5wm4hcBGQCu4Gh/sPbAP8WkWxcEnsySO8nY4wxYWQD5YwxJoYVNlCuzCQIEUkFthzDKeoCO0sonHCLplghuuKNplghuuKNplghuuI9llibqGq9YG+UmQRxrERkaUFZNNJEU6wQXfFGU6wQXfFGU6wQXfGGK1abrM8YY0xQliCMMcYEZQnisMleB1AM0RQrRFe80RQrRFe80RQrRFe8YYnV2iCMMcYEZSUIY4wxQVmCMMYYE1TMJ4iiFjWKJCLSWEQWiMgaEVktIrd7HVNRRCRORL4Vkfe9jqUoIlLTP6vwOhFZKyJneB1TQURklP93wCcir4tI8abpDDMRmSoiO0TEF7CttojMFZEN/ufwLqgcogJifcr/e7BKRGaLSE0vYwwULN6A9+4UEfVPUXTMYjpBBCxqdD7QFhgiIm29japQmcCdqtoW6AbcEuHxAtyOf46tKPAM8JGqtgbiidC4RaQhcBuQqKrtcVPZXOFtVEeYBvTLt20MMF9VWwDz/a8jwTSOjHUu0F5VTwPWA/eWdlCFmMaR8eJfLqEv8FNJXSimEwRRtqiRqm5T1eX+n/fjbmDB1tiICCLSCLgAN1NvRBORGkB3YAqAqh5S1b3eRlWo8kBlESkPVAF+8TiePFR1IW5+tUADcFP6438Ous5LaQsWq6p+oqqZ/pdf42ajjggF/NsCPA3cDZRYz6NYTxChLmoUcUSkKW4K9G+8jaRQE3C/sNleBxKCZkAq8B9/ldhLIlLV66CC8U+FPx73TXEbsE9VP/E2qpCcoKrb/D//CpzgZTDFcD3woddBFEZEBgBbVXVlSZ431hNEVBKRasDbwEhV/c3reIIRkf7ADlVd5nUsISoPnA5MUtWOwO9EThVIHv66+wG4pHYSUFVErvY2quJR178+4vvYi8j9uKrdGV7HUhARqQLcB/y1pM8d6wmiyEWNIo2IVMAlhxmq+l+v4ylEEnCRiGzGVd31EpFXvQ2pUClAiqrmlMjewiWMSHQusElVU1U1A/gvcKbHMYVie84aMP7nHR7HUygRGQr0B67SyB4wdgruy8JK/99bI2C5iJx4rCeO9QRR5KJGkUREBFdHvlZV/+l1PIVR1XtVtZGqNsX9u36qqhH7LVdVfwV+FpFW/k29idxFqn4CuolIFf/vRG8itEE9nznAtf6frwXe9TCWQolIP1z16EWq+ofX8RRGVb9T1fqq2tT/95YCnO7/nT4mMZ0g/I1QOYsarQVmqepqb6MqVBLwZ9y38RX+x5+8DqoMGQHMEJFVQALwuMfxBOUv5bwFLAe+w/0dR9S0ECLyOrAIaCUiKSJyA/Ak0EdENuBKQU96GWOOAmJ9HqgOzPX/nb3gaZABCog3PNeK7JKTMcYYr8R0CcIYY0zBLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKAsQRhTDCKSFdDFeEVJzgAsIk2DzdBpjFfKex2AMVEmXVUTvA7CmNJgJQhjSoCIbBaRcSLynYgsFpFT/dubisin/nUF5ovIyf7tJ/jXGVjpf+RMlREnIi/613r4REQqe/ahTMyzBGFM8VTOV8V0ecB7+1S1A24U7gT/tueAl/3rCswAnvVvfxb4TFXjcXM+5YzgbwFMVNV2wF7gkjB/HmMKZCOpjSkGEUlT1WpBtm8GeqnqRv+Eir+qah0R2Qk0UNUM//ZtqlpXRFKBRqp6MOAcTYG5/gV1EJF7gAqq+rfwfzJjjmQlCGNKjhbwc3EcDPg5C2snNB6yBGFMybk84HmR/+evOLwc6FXA5/6f5wN/gdx1u2uUVpDGhMq+nRhTPJVFZEXA649UNaeray3/TLAHgSH+bSNwq9SNxq1Yd51/++3AZP9MnFm4ZLENYyKItUEYUwL8bRCJqrrT61iMKSlWxWSMMSYoK0EYY4wJykoQxhhjgrIEYYwxJihLEMYYY4KyBGGMMSYoSxDGGGOC+n+aeIBGM0ewOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pretrained_valid_acc, 'b', label=\"the Pretrained accuracy\")\n",
    "plt.plot(from_scratch_valid_acc, 'r', label=\"From scratch accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " ALTEGRAD_2021_transfer_learning_tabaai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
